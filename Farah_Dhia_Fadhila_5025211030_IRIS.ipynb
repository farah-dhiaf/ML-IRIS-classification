{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Farah Dhia Fadhila</br>\n",
        "NRP: 5025211030</br>\n",
        "Kelas: Pembelajaran Mesin C"
      ],
      "metadata": {
        "id": "xExyqHW2-2Ym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SW8xOrV0svy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8638a9c-e07a-43a6-90cf-5a845b7c6684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_train = pd.read_csv('./drive/MyDrive/ML/IRIS_Train.csv')\n",
        "data_test = pd.read_csv('./drive/MyDrive/ML/IRIS_Test.csv')"
      ],
      "metadata": {
        "id": "FwahQlEhtXWT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train)\n",
        "print(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BsRgyxjuFYq",
        "outputId": "a296d61c-b034-4870-9852-e96b6761830d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.4          3.9           1.7          0.4     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "115           6.8          3.2           5.9          2.3  Iris-virginica\n",
            "116           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "117           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "118           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "119           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "\n",
            "[120 rows x 5 columns]\n",
            "    sepal_length  sepal_width  petal_length  petal_width          species\n",
            "0            5.0          3.6           1.4          0.2      Iris-setosa\n",
            "1            4.9          3.1           1.5          0.1      Iris-setosa\n",
            "2            5.8          4.0           1.2          0.2      Iris-setosa\n",
            "3            5.1          3.8           1.5          0.3      Iris-setosa\n",
            "4            4.8          3.4           1.9          0.2      Iris-setosa\n",
            "5            4.7          3.2           1.6          0.2      Iris-setosa\n",
            "6            4.9          3.1           1.5          0.1      Iris-setosa\n",
            "7            5.1          3.4           1.5          0.2      Iris-setosa\n",
            "8            5.1          3.8           1.9          0.4      Iris-setosa\n",
            "9            5.0          3.3           1.4          0.2      Iris-setosa\n",
            "10           6.5          2.8           4.6          1.5  Iris-versicolor\n",
            "11           5.2          2.7           3.9          1.4  Iris-versicolor\n",
            "12           5.6          2.9           3.6          1.3  Iris-versicolor\n",
            "13           5.6          2.5           3.9          1.1  Iris-versicolor\n",
            "14           6.4          2.9           4.3          1.3  Iris-versicolor\n",
            "15           5.7          2.6           3.5          1.0  Iris-versicolor\n",
            "16           5.4          3.0           4.5          1.5  Iris-versicolor\n",
            "17           5.5          2.5           4.0          1.3  Iris-versicolor\n",
            "18           5.6          2.7           4.2          1.3  Iris-versicolor\n",
            "19           5.7          2.8           4.1          1.3  Iris-versicolor\n",
            "20           6.5          3.0           5.8          2.2   Iris-virginica\n",
            "21           7.2          3.6           6.1          2.5   Iris-virginica\n",
            "22           5.8          2.8           5.1          2.4   Iris-virginica\n",
            "23           6.0          2.2           5.0          1.5   Iris-virginica\n",
            "24           6.7          3.3           5.7          2.1   Iris-virginica\n",
            "25           7.2          3.0           5.8          1.6   Iris-virginica\n",
            "26           6.1          2.6           5.6          1.4   Iris-virginica\n",
            "27           6.9          3.1           5.4          2.1   Iris-virginica\n",
            "28           6.7          3.3           5.7          2.5   Iris-virginica\n",
            "29           5.9          3.0           5.1          1.8   Iris-virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data train: \\n{data_train.describe()}\\n\")\n",
        "print(f\"data test: \\n{data_test.describe()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBJI1N5uIVe",
        "outputId": "ba5664bb-228e-4503-cf17-1c54c7260c58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data train: \n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count    120.000000   120.000000    120.000000   120.000000\n",
            "mean       5.865833     3.050833      3.770833     1.205000\n",
            "std        0.851938     0.436756      1.785958     0.758686\n",
            "min        4.300000     2.000000      1.000000     0.100000\n",
            "25%        5.100000     2.800000      1.575000     0.300000\n",
            "50%        5.800000     3.000000      4.400000     1.300000\n",
            "75%        6.400000     3.300000      5.100000     1.800000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n",
            "\n",
            "data test: \n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count     30.000000    30.000000     30.000000    30.000000\n",
            "mean       5.753333     3.066667      3.710000     1.173333\n",
            "std        0.730957     0.427772      1.704022     0.793479\n",
            "min        4.700000     2.200000      1.200000     0.100000\n",
            "25%        5.100000     2.800000      1.675000     0.225000\n",
            "50%        5.650000     3.000000      4.050000     1.300000\n",
            "75%        6.325000     3.300000      5.100000     1.575000\n",
            "max        7.200000     4.000000      6.100000     2.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data train:\\n{data_train.isna().sum()}\\n\")\n",
        "print(f\"data test:\\n{data_test.isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKu178de8gCR",
        "outputId": "ff5587fd-aa78-43f5-ec5c-17ca25034b87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data train:\n",
            "sepal_length    0\n",
            "sepal_width     0\n",
            "petal_length    0\n",
            "petal_width     0\n",
            "species         0\n",
            "dtype: int64\n",
            "\n",
            "data test:\n",
            "sepal_length    0\n",
            "sepal_width     0\n",
            "petal_length    0\n",
            "petal_width     0\n",
            "species         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data train:\\n{data_train['species'].unique()}\\n\")\n",
        "print(f\"data test:\\n{data_test['species'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onWSM5479dTf",
        "outputId": "aebb5d75-6b37-477b-963a-f1b383255950"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data train:\n",
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
            "\n",
            "data test:\n",
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data_train['species'] = label_encoder.fit_transform(data_train['species'])\n",
        "data_test['species'] = label_encoder.fit_transform(data_test['species'])\n",
        "\n",
        "print(data_train['species'])\n",
        "print(data_test['species'])\n"
      ],
      "metadata": {
        "id": "EEmNqQNlvNX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb02ffee-a12e-4fe7-c501-4eed857b08b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "115    2\n",
            "116    2\n",
            "117    2\n",
            "118    2\n",
            "119    2\n",
            "Name: species, Length: 120, dtype: int64\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    1\n",
            "11    1\n",
            "12    1\n",
            "13    1\n",
            "14    1\n",
            "15    1\n",
            "16    1\n",
            "17    1\n",
            "18    1\n",
            "19    1\n",
            "20    2\n",
            "21    2\n",
            "22    2\n",
            "23    2\n",
            "24    2\n",
            "25    2\n",
            "26    2\n",
            "27    2\n",
            "28    2\n",
            "29    2\n",
            "Name: species, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data train:\\n{data_train['species'].unique()}\\n\")\n",
        "print(f\"data test:\\n{data_test['species'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAzUL6c_-aHx",
        "outputId": "5b4d9a6e-59ae-430c-888a-79b1b99989b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data train:\n",
            "[0 1 2]\n",
            "\n",
            "data test:\n",
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train.iloc[:, :-1]\n",
        "y_train = data_train.iloc[:, -1]\n",
        "\n",
        "X_test = data_test.iloc[:, :-1]\n",
        "y_test = data_test.iloc[:, -1]\n",
        "\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk4AuO38uNob",
        "outputId": "9c056ed7-8f8b-4378-9f5c-503132903e49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "115    2\n",
            "116    2\n",
            "117    2\n",
            "118    2\n",
            "119    2\n",
            "Name: species, Length: 120, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "dataplot = sns.heatmap(data_train.corr(), cmap=\"YlGnBu\", annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "kIsEJX-DuZsl",
        "outputId": "dd78f0bc-b597-4e0b-dd77-93753f12024e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.countplot(x='species',data=data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "w0-eIfG8v3fr",
        "outputId": "4e9abb1f-cba1-4016-a94a-610275e46511"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='species', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.countplot(x='species',data=data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "JlbsGMlA5XXW",
        "outputId": "fd10be3b-98ae-4997-f64a-27a3caf92278"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='species', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skenario 1 (Tanpa normalisasi data)"
      ],
      "metadata": {
        "id": "HbiwCoi_5vxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "from imblearn.metrics import specificity_score"
      ],
      "metadata": {
        "id": "ar9pUZuh6ojV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decision Tree criterion=gini\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier(criterion='gini')\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dtc.predict(X_test)\n",
        "\n",
        "dtc_train_acc = accuracy_score(y_train, dtc.predict(X_train))\n",
        "dtc_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Decision Tree is : {dtc_train_acc}\")\n",
        "print(f\"Test accuracy of Decision Tree is : {dtc_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OciX2NB74hOb",
        "outputId": "41a70210-9a3e-4892-9b5f-5147458f6082"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Decision Tree is : 1.0\n",
            "Test accuracy of Decision Tree is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  2  8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9444444444444445\n",
            "F-Measure: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decision Tree criterion=entropy\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier(criterion='entropy')\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dtc.predict(X_test)\n",
        "\n",
        "dtc_train_acc = accuracy_score(y_train, dtc.predict(X_train))\n",
        "dtc_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Decision Tree is : {dtc_train_acc}\")\n",
        "print(f\"Test accuracy of Decision Tree is : {dtc_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "JEcLPYdc8qhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b2fd5a-8b80-406c-ba75-ab9b4d67172c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Decision Tree is : 1.0\n",
            "Test accuracy of Decision Tree is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  2  8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9444444444444445\n",
            "F-Measure: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=3\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "m26X247N5-kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b41b934-619e-4b65-e6a9-91ac710f3d12"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.9583333333333334\n",
            "Test accuracy of KNN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=5\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(X_train, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "HgS7VCcF8HxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa299e2-76e8-4cad-98e5-1cbe7fcb4edd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.975\n",
            "Test accuracy of KNN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=7\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=7)\n",
        "neigh.fit(X_train, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "bvyEZWnA8KfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15003fd-67d0-44de-d2ab-7f0ffb5c553e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.975\n",
            "Test accuracy of KNN is : 1.0\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Recall: 1.0\n",
            "Specificity: 1.0\n",
            "Precision: 1.0\n",
            "F-Measure: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "nb_train_acc = accuracy_score(y_train, nb.predict(X_train))\n",
        "nb_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Naive Bayes is : {nb_train_acc}\")\n",
        "print(f\"Test accuracy of Naive Bayes is : {nb_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "IseqHGHT82DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76ff935-b5b9-442f-edab-cd05b925b11e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Naive Bayes is : 0.9666666666666667\n",
            "Test accuracy of Naive Bayes is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  2  8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9444444444444445\n",
            "F-Measure: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=linear\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "Cx48ffUW9B08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2fa272-8fd7-4639-e9ff-164dc78ddf0c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.975\n",
            "Test accuracy of SVM is : 1.0\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Recall: 1.0\n",
            "Specificity: 1.0\n",
            "Precision: 1.0\n",
            "F-Measure: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=polynomial\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='poly')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "z2F4jjfM9OP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d004dda-1cce-4d16-a3c3-c4fb439f6497"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.975\n",
            "Test accuracy of SVM is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=rbf\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='rbf')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "J2uSIlus9STA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027f8516-4fda-40e8-febf-4eb0e66786a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.9583333333333334\n",
            "Test accuracy of SVM is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=sigmoid\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='sigmoid')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "Afb7UHZr9VRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab17144-e3e4-4aef-e71a-8750f22c9ac9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.08333333333333333\n",
            "Test accuracy of SVM is : 0.03333333333333333\n",
            "[[ 1  0  9]\n",
            " [ 7  0  3]\n",
            " [10  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.10      0.07        10\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.03        30\n",
            "   macro avg       0.02      0.03      0.02        30\n",
            "weighted avg       0.02      0.03      0.02        30\n",
            "\n",
            "Recall: 0.03333333333333333\n",
            "Specificity: 0.5166666666666666\n",
            "Precision: 0.018518518518518517\n",
            "F-Measure: 0.023809523809523808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ANN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train_one_hot, epochs=100, batch_size=32)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "# ann_train_acc = accuracy_score(y_train, y_train_classes)\n",
        "ann_test_acc = accuracy_score(y_test_classes, y_pred_classes)\n",
        "\n",
        "print(f\"Test accuracy of ANN is : {ann_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test_classes, y_pred_classes, average='macro')}\")"
      ],
      "metadata": {
        "id": "3gzkBAt79ZOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d44406-c03b-40bb-8d6b-df019c9e9b43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 7ms/step - loss: 1.1486 - accuracy: 0.1083\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1414 - accuracy: 0.1750\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1342 - accuracy: 0.3167\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1272 - accuracy: 0.5500\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1224 - accuracy: 0.6583\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1178 - accuracy: 0.6583\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1143 - accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1111 - accuracy: 0.6167\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1088 - accuracy: 0.5917\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1059 - accuracy: 0.5750\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1032 - accuracy: 0.5167\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1008 - accuracy: 0.3333\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.3333\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0953 - accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0946 - accuracy: 0.3417\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0938 - accuracy: 0.4167\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0928 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0918 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0910 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0903 - accuracy: 0.5500\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.5583\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0888 - accuracy: 0.5500\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0880 - accuracy: 0.5167\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0873 - accuracy: 0.5083\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0864 - accuracy: 0.5083\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0856 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0847 - accuracy: 0.5167\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0839 - accuracy: 0.5167\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0830 - accuracy: 0.5167\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0821 - accuracy: 0.5250\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0812 - accuracy: 0.5250\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0802 - accuracy: 0.5250\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0792 - accuracy: 0.5333\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0782 - accuracy: 0.5417\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0772 - accuracy: 0.5250\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0757 - accuracy: 0.5333\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0744 - accuracy: 0.5250\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0729 - accuracy: 0.5500\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0715 - accuracy: 0.6167\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0698 - accuracy: 0.8917\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0682 - accuracy: 0.8917\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0663 - accuracy: 0.9000\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0645 - accuracy: 0.8917\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0623 - accuracy: 0.8833\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0603 - accuracy: 0.8833\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0578 - accuracy: 0.8750\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0554 - accuracy: 0.8667\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0527 - accuracy: 0.8750\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0500 - accuracy: 0.8833\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0469 - accuracy: 0.8917\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0441 - accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0404 - accuracy: 0.8750\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0370 - accuracy: 0.8333\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0333 - accuracy: 0.8250\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0294 - accuracy: 0.8667\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0255 - accuracy: 0.8750\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0211 - accuracy: 0.8583\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0164 - accuracy: 0.8500\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0117 - accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.8583\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0013 - accuracy: 0.8583\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9962 - accuracy: 0.7750\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9902 - accuracy: 0.7333\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9845 - accuracy: 0.7250\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9787 - accuracy: 0.7167\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9718 - accuracy: 0.7167\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9656 - accuracy: 0.7167\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9589 - accuracy: 0.7083\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9521 - accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9451 - accuracy: 0.6917\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9377 - accuracy: 0.7083\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9306 - accuracy: 0.7250\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9234 - accuracy: 0.6750\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9155 - accuracy: 0.6917\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9079 - accuracy: 0.6833\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9002 - accuracy: 0.6833\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8922 - accuracy: 0.6917\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8841 - accuracy: 0.6917\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.7250\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8684 - accuracy: 0.7667\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8609 - accuracy: 0.7667\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8523 - accuracy: 0.8500\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8443 - accuracy: 0.8583\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8363 - accuracy: 0.8750\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8282 - accuracy: 0.8750\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8203 - accuracy: 0.8750\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8123 - accuracy: 0.8750\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8043 - accuracy: 0.9000\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7964 - accuracy: 0.9083\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7886 - accuracy: 0.9083\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7811 - accuracy: 0.9250\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7730 - accuracy: 0.9167\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7654 - accuracy: 0.9250\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7578 - accuracy: 0.9250\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.9167\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.9000\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.9167\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7284 - accuracy: 0.9083\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Test accuracy of ANN is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 2  8  0]\n",
            " [ 0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        10\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9444444444444445\n",
            "F-Measure: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skenario 2 (Normalisasi Min-Max Scalling)"
      ],
      "metadata": {
        "id": "QncIFWXy53Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "QfNgfem0wJ_M"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decision Tree criterion=gini\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier(criterion='gini')\n",
        "dtc.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = dtc.predict(X_test_scaled)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "dtc_train_acc = accuracy_score(y_train, dtc.predict(X_train_scaled))\n",
        "dtc_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Decision Tree is : {dtc_train_acc}\")\n",
        "print(f\"Test accuracy of Decision Tree is : {dtc_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "L4MidnImxE3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6db5b2-d783-48c7-ddf4-bfd9dfc3528b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Decision Tree is : 1.0\n",
            "Test accuracy of Decision Tree is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9333333333333332\n",
            "F-Measure: 0.9333333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decision Tree criterion=entropy\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier(criterion='entropy')\n",
        "dtc.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = dtc.predict(X_test_scaled)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "dtc_train_acc = accuracy_score(y_train, dtc.predict(X_train_scaled))\n",
        "dtc_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Decision Tree is : {dtc_train_acc}\")\n",
        "print(f\"Test accuracy of Decision Tree is : {dtc_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "kQQ7m1nTJXPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658354f9-15e8-4c67-b7b2-32400f855f9c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Decision Tree is : 1.0\n",
            "Test accuracy of Decision Tree is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9333333333333332\n",
            "F-Measure: 0.9333333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=3\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test_scaled)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train_scaled))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "M0YMPjpPJwio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ee101f-5f71-4daf-ea17-5396db514e76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.975\n",
            "Test accuracy of KNN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=5\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test_scaled)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train_scaled))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "HVi7vRu3J7Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0875efd8-2b0a-4408-b5f9-575effa6f6c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.9833333333333333\n",
            "Test accuracy of KNN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KNN k=7\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=7)\n",
        "neigh.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = neigh.predict(X_test_scaled)\n",
        "\n",
        "neigh_train_acc = accuracy_score(y_train, neigh.predict(X_train_scaled))\n",
        "neigh_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of KNN is : {neigh_train_acc}\")\n",
        "print(f\"Test accuracy of KNN is : {neigh_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "2-jVhl2YJ_b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e52bd43-f96a-46db-9a10-54e80f3362d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of KNN is : 0.9833333333333333\n",
            "Test accuracy of KNN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test_scaled)\n",
        "\n",
        "nb_train_acc = accuracy_score(y_train, nb.predict(X_train_scaled))\n",
        "nb_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of Naive Bayes is : {nb_train_acc}\")\n",
        "print(f\"Test accuracy of Naive Bayes is : {nb_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "iwtmjb0TKFTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822d7b54-e082-46c6-cf6b-5634203707e1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of Naive Bayes is : 0.9666666666666667\n",
            "Test accuracy of Naive Bayes is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=linear\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train_scaled))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "Tx3rkkQLKNhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed0bccb-33f8-4663-f3ba-ff2374e0157a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.9833333333333333\n",
            "Test accuracy of SVM is : 1.0\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Recall: 1.0\n",
            "Specificity: 1.0\n",
            "Precision: 1.0\n",
            "F-Measure: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=polynomial\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='poly')\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train_scaled))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "UEzWKMnZKTQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbb3d91-177a-4320-f6fb-1d2eb24ccb8b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.975\n",
            "Test accuracy of SVM is : 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  2  8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "Recall: 0.9333333333333332\n",
            "Specificity: 0.9666666666666667\n",
            "Precision: 0.9444444444444445\n",
            "F-Measure: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=rbf\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='rbf')\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train_scaled))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "FFfhlNkDKYlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e678a7-3645-4ed1-9dcb-c837342ee830"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.9666666666666667\n",
            "Test accuracy of SVM is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SVM kernel=sigmoid\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='sigmoid')\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train_scaled))\n",
        "svm_test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
        "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test, y_pred, average='macro')}\")"
      ],
      "metadata": {
        "id": "YhgN_ZC_Kbsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a7271d-eb9a-43a1-bfd2-3d8cc75782b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy of SVM is : 0.275\n",
            "Test accuracy of SVM is : 0.4\n",
            "[[10  0  0]\n",
            " [ 1  2  7]\n",
            " [ 7  3  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71        10\n",
            "           1       0.40      0.20      0.27        10\n",
            "           2       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.40        30\n",
            "   macro avg       0.32      0.40      0.33        30\n",
            "weighted avg       0.32      0.40      0.33        30\n",
            "\n",
            "Recall: 0.39999999999999997\n",
            "Specificity: 0.7000000000000001\n",
            "Precision: 0.31851851851851853\n",
            "F-Measure: 0.326984126984127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ANN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dense(6, activation='relu',))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train_scaled, y_train_one_hot, epochs=100, batch_size=32)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "# Evaluasi model\n",
        "ann_test_acc = accuracy_score(y_test_classes, y_pred_classes)\n",
        "\n",
        "print(f\"Test accuracy of ANN is : {ann_test_acc}\")\n",
        "\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "print(f\"Recall: {recall_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"Specificity: {specificity_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"Precision: {precision_score(y_test_classes, y_pred_classes, average='macro')}\")\n",
        "print(f\"F-Measure: {f1_score(y_test_classes, y_pred_classes, average='macro')}\")\n"
      ],
      "metadata": {
        "id": "eUOxTyCnKh6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d83fd48-291f-42eb-c5af-2c5d1c6f885d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 1.0460 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0386 - accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0313 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0242 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.3583\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0098 - accuracy: 0.4167\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0021 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9945 - accuracy: 0.6167\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9865 - accuracy: 0.6333\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9783 - accuracy: 0.6583\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9700 - accuracy: 0.6583\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9616 - accuracy: 0.6583\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9526 - accuracy: 0.6583\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9433 - accuracy: 0.6583\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9339 - accuracy: 0.6583\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9243 - accuracy: 0.6583\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9142 - accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9041 - accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8937 - accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8843 - accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8733 - accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8631 - accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8530 - accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8426 - accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8324 - accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8118 - accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8017 - accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7916 - accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7814 - accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7718 - accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7620 - accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7521 - accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7333 - accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7238 - accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7148 - accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6750\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7083\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7083\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7167\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7167\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7333\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7583\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7750\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7833\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7833\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7833\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7833\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7833\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.8167\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.8167\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.8167\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8167\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8167\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8167\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8417\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8167\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8250\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8583\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8750\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8833\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8667\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8583\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8500\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8583\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.9000\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.9083\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.9083\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.9250\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.9083\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.9167\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.9250\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.9250\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.9250\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.9250\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.9333\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.9333\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.9333\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.9250\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.9333\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.9333\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.9333\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.9333\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Test accuracy of ANN is : 0.9666666666666667\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Recall: 0.9666666666666667\n",
            "Specificity: 0.9833333333333334\n",
            "Precision: 0.9696969696969697\n",
            "F-Measure: 0.9665831244778613\n"
          ]
        }
      ]
    }
  ]
}